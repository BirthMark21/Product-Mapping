#!/usr/bin/env python3
"""
Test script to verify that created_at values come from actual source tables
This will show the created_at values from all 7 tables to ensure they're real timestamps
"""

import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import os
import config.setting as settings
from utils.db_connector import get_db_engine
from pipeline.data_loader import load_all_product_data_from_clickhouse, load_all_product_data_from_supabase

# Load environment variables
load_dotenv()

def test_created_at_sources():
    """Test that created_at values come from actual source tables"""
    
    print("ğŸ” Testing Created At Sources")
    print("=" * 60)
    print("ğŸ“¥ Goal: Verify created_at values come from actual source tables")
    print("=" * 60)
    
    try:
        # Connect to databases
        supabase_engine = get_db_engine('supabase')
        clickhouse_engine = get_db_engine('clickhouse')
        
        print("ğŸ“Š Step 1: Testing Supabase created_at values...")
        
        # Test Supabase data
        supabase_df = load_all_product_data_from_supabase(supabase_engine)
        if not supabase_df.empty:
            print(f"âœ… Supabase: {len(supabase_df)} records loaded")
            
            # Show created_at statistics
            if 'created_at' in supabase_df.columns:
                created_at_stats = supabase_df['created_at'].describe()
                print(f"ğŸ“… Supabase created_at statistics:")
                print(f"   ğŸ“‹ Count: {created_at_stats['count']}")
                print(f"   ğŸ“‹ Min: {created_at_stats['min']}")
                print(f"   ğŸ“‹ Max: {created_at_stats['max']}")
                
                # Show sample created_at values
                sample_created_at = supabase_df['created_at'].dropna().head(5)
                print(f"ğŸ“‹ Sample Supabase created_at values:")
                for i, timestamp in enumerate(sample_created_at, 1):
                    print(f"   {i}. {timestamp}")
            else:
                print("âŒ created_at column not found in Supabase data")
        else:
            print("âš ï¸  No Supabase data loaded")
        
        print("\nğŸ“Š Step 2: Testing ClickHouse created_at values...")
        
        # Test ClickHouse data
        clickhouse_df = load_all_product_data_from_clickhouse(clickhouse_engine)
        if not clickhouse_df.empty:
            print(f"âœ… ClickHouse: {len(clickhouse_df)} records loaded")
            
            # Show created_at statistics
            if 'created_at' in clickhouse_df.columns:
                created_at_stats = clickhouse_df['created_at'].describe()
                print(f"ğŸ“… ClickHouse created_at statistics:")
                print(f"   ğŸ“‹ Count: {created_at_stats['count']}")
                print(f"   ğŸ“‹ Min: {created_at_stats['min']}")
                print(f"   ğŸ“‹ Max: {created_at_stats['max']}")
                
                # Show sample created_at values
                sample_created_at = clickhouse_df['created_at'].dropna().head(5)
                print(f"ğŸ“‹ Sample ClickHouse created_at values:")
                for i, timestamp in enumerate(sample_created_at, 1):
                    print(f"   {i}. {timestamp}")
            else:
                print("âŒ created_at column not found in ClickHouse data")
        else:
            print("âš ï¸  No ClickHouse data loaded")
        
        print("\nğŸ“Š Step 3: Testing combined data...")
        
        # Combine data
        all_data_frames = []
        if not clickhouse_df.empty:
            all_data_frames.append(clickhouse_df)
        if not supabase_df.empty:
            all_data_frames.append(supabase_df)
        
        if all_data_frames:
            combined_df = pd.concat(all_data_frames, ignore_index=True)
            print(f"âœ… Combined data: {len(combined_df)} total records")
            
            if 'created_at' in combined_df.columns:
                created_at_stats = combined_df['created_at'].describe()
                print(f"ğŸ“… Combined created_at statistics:")
                print(f"   ğŸ“‹ Count: {created_at_stats['count']}")
                print(f"   ğŸ“‹ Min: {created_at_stats['min']}")
                print(f"   ğŸ“‹ Max: {created_at_stats['max']}")
                
                # Check if created_at values are realistic (not all current time)
                unique_timestamps = combined_df['created_at'].nunique()
                print(f"ğŸ“‹ Unique timestamps: {unique_timestamps}")
                
                if unique_timestamps > 1:
                    print("âœ… Good: Multiple unique timestamps found (real data)")
                else:
                    print("âš ï¸  Warning: Only one unique timestamp found (might be current time)")
                
                # Show date range
                min_date = combined_df['created_at'].min()
                max_date = combined_df['created_at'].max()
                print(f"ğŸ“… Date range: {min_date} to {max_date}")
                
            else:
                print("âŒ created_at column not found in combined data")
        else:
            print("âŒ No data to combine")
        
        print("\nâœ… Created At Source Test Completed!")
        
    except Exception as e:
        print(f"âŒ Error testing created_at sources: {e}")

def main():
    """Main function"""
    print("ğŸš€ Testing Created At Sources")
    print("=" * 60)
    print("ğŸ“¥ Goal: Verify created_at values come from actual source tables")
    print("ğŸ¯ This ensures parent-child relationships use real timestamps")
    print("=" * 60)
    
    test_created_at_sources()

if __name__ == "__main__":
    main()
