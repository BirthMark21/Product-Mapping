{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Product Segmentation Analysis\n",
        "This notebook performs comprehensive product segmentation analysis using Superset API to fetch data from ClickHouse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Superset API Configuration\n",
        "SUPERSET_URL = \"http://64.227.129.135:8088\"\n",
        "ACCESS_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmcmVzaCI6dHJ1ZSwiaWF0IjoxNzU5MTM5MzAwLCJqdGkiOiIzMGZkYTJmNS1lMmIxLTQ2ZWYtYjQwNy01YTJiNWE1MjRlZTgiLCJ0eXBlIjoiYWNjZXNzIiwic3ViIjoyNCwibmJmIjoxNzU5MTM5MzAwLCJjc3JmIjoiNDMzMmE5NzMtYTkxMi00MzJlLTkyZjctYTJkOTIyMzljODRjIiwiZXhwIjo0OTEyNzM5MzAwfQ.cQA_bjBCdZGzbnmlo3nl96vxrrIPO0sv-47x6TrDUnY\"\n",
        "DATABASE_ID = 1\n",
        "SCHEMA = \"chipchip\"\n",
        "\n",
        "print(\"Superset API configuration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_superset_request(sql_query, client_id_prefix=\"prod\"):\n",
        "    \"\"\"Make request to Superset API\"\"\"\n",
        "    try:\n",
        "        unique_client_id = f\"{client_id_prefix}_{uuid.uuid4().hex[:6]}\"\n",
        "        \n",
        "        payload = {\n",
        "            \"client_id\": unique_client_id,\n",
        "            \"database_id\": DATABASE_ID,\n",
        "            \"json\": True,\n",
        "            \"runAsync\": False,\n",
        "            \"schema\": SCHEMA,\n",
        "            \"sql\": sql_query,\n",
        "            \"tab\": \"\",\n",
        "            \"expand_data\": True\n",
        "        }\n",
        "        \n",
        "        headers = {\n",
        "            'Accept': 'application/json',\n",
        "            'Content-Type': 'application/json',\n",
        "            'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
        "            'User-Agent': 'chipchip/product-segmentation'\n",
        "        }\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{SUPERSET_URL}/api/v1/sqllab/execute/\",\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            verify=False\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if 'data' in result and result['data']:\n",
        "                return result['data']\n",
        "            else:\n",
        "                print(f\"WARNING: Query returned no data\")\n",
        "                return []\n",
        "        else:\n",
        "            print(f\"ERROR: Superset API request failed with status {response.status_code}\")\n",
        "            return []\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to execute Superset query. Error: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"Superset API function defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch Product Data\n",
        "print(\"Fetching product data from ClickHouse...\")\n",
        "\n",
        "# Fetch product variations\n",
        "sql_query = '''\n",
        "SELECT \n",
        "    id,\n",
        "    product_id,\n",
        "    sku,\n",
        "    image_url,\n",
        "    stock,\n",
        "    toString(created_at) AS created_at,\n",
        "    toString(updated_at) AS updated_at,\n",
        "    deleted_at,\n",
        "    status,\n",
        "    weight,\n",
        "    stock_alert,\n",
        "    toString(_peerdb_synced_at) AS _peerdb_synced_at,\n",
        "    _peerdb_is_deleted,\n",
        "    _peerdb_version\n",
        "FROM \"chipchip\".\"product_variations\"\n",
        "WHERE _peerdb_is_deleted = 0\n",
        "ORDER BY created_at DESC\n",
        "LIMIT 1000\n",
        "'''\n",
        "\n",
        "product_variations_data = make_superset_request(sql_query, \"pv\")\n",
        "if product_variations_data:\n",
        "    product_variations_df = pd.DataFrame(product_variations_data)\n",
        "    print(f\"‚úÖ Fetched {len(product_variations_df)} product variations\")\n",
        "    print(f\"Columns: {list(product_variations_df.columns)}\")\n",
        "    print(f\"Sample data:\")\n",
        "    print(product_variations_df.head())\n",
        "else:\n",
        "    print(\"‚ùå No product variations data fetched\")\n",
        "    product_variations_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch Product Names\n",
        "print(\"Fetching product names...\")\n",
        "\n",
        "sql_query = '''\n",
        "SELECT \n",
        "    id,\n",
        "    name,\n",
        "    category_id,\n",
        "    created_by,\n",
        "    toString(created_at) AS created_at,\n",
        "    toString(updated_at) AS updated_at,\n",
        "    deleted_at,\n",
        "    measuring_unit,\n",
        "    toString(_peerdb_synced_at) AS _peerdb_synced_at,\n",
        "    _peerdb_is_deleted,\n",
        "    _peerdb_version\n",
        "FROM \"chipchip\".\"product_names\"\n",
        "WHERE _peerdb_is_deleted = 0\n",
        "ORDER BY name\n",
        "LIMIT 1000\n",
        "'''\n",
        "\n",
        "product_names_data = make_superset_request(sql_query, \"pn\")\n",
        "if product_names_data:\n",
        "    product_names_df = pd.DataFrame(product_names_data)\n",
        "    print(f\"‚úÖ Fetched {len(product_names_df)} product names\")\n",
        "    print(f\"Sample product names:\")\n",
        "    print(product_names_df['name'].head(10).tolist())\n",
        "else:\n",
        "    print(\"‚ùå No product names data fetched\")\n",
        "    product_names_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic Product Data Visualization\n",
        "if not product_variations_df.empty:\n",
        "    print(\"Creating basic product data visualizations...\")\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Product Variations Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Stock Distribution\n",
        "    if 'stock' in product_variations_df.columns:\n",
        "        product_variations_df['stock'] = pd.to_numeric(product_variations_df['stock'], errors='coerce')\n",
        "        axes[0, 0].hist(product_variations_df['stock'].dropna(), bins=20, alpha=0.7, edgecolor='black')\n",
        "        axes[0, 0].set_xlabel('Stock Quantity')\n",
        "        axes[0, 0].set_ylabel('Frequency')\n",
        "        axes[0, 0].set_title('Stock Distribution')\n",
        "    \n",
        "    # 2. Weight Distribution\n",
        "    if 'weight' in product_variations_df.columns:\n",
        "        product_variations_df['weight'] = pd.to_numeric(product_variations_df['weight'], errors='coerce')\n",
        "        axes[0, 1].hist(product_variations_df['weight'].dropna(), bins=20, alpha=0.7, edgecolor='black')\n",
        "        axes[0, 1].set_xlabel('Weight')\n",
        "        axes[0, 1].set_ylabel('Frequency')\n",
        "        axes[0, 1].set_title('Weight Distribution')\n",
        "    \n",
        "    # 3. Status Distribution\n",
        "    if 'status' in product_variations_df.columns:\n",
        "        status_counts = product_variations_df['status'].value_counts()\n",
        "        axes[1, 0].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "        axes[1, 0].set_title('Product Status Distribution')\n",
        "    \n",
        "    # 4. Stock vs Weight\n",
        "    if 'stock' in product_variations_df.columns and 'weight' in product_variations_df.columns:\n",
        "        axes[1, 1].scatter(product_variations_df['stock'], product_variations_df['weight'], alpha=0.6)\n",
        "        axes[1, 1].set_xlabel('Stock Quantity')\n",
        "        axes[1, 1].set_ylabel('Weight')\n",
        "        axes[1, 1].set_title('Stock vs Weight')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Basic product visualizations created!\")\n",
        "else:\n",
        "    print(\"‚ùå No product variations data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch Orders Data for User Segmentation\n",
        "print(\"Fetching orders data...\")\n",
        "\n",
        "sql_query = '''\n",
        "SELECT \n",
        "    id,\n",
        "    personal_cart_id,\n",
        "    groups_carts_id,\n",
        "    status,\n",
        "    total_amount,\n",
        "    toString(created_at) AS created_at,\n",
        "    toString(updated_at) AS updated_at,\n",
        "    deleted_at,\n",
        "    location_id,\n",
        "    response,\n",
        "    payment_method,\n",
        "    discount,\n",
        "    discount_type,\n",
        "    discount_rule_id,\n",
        "    meta,\n",
        "    bill_id,\n",
        "    secondary_order_location_id,\n",
        "    toString(_peerdb_synced_at) AS _peerdb_synced_at,\n",
        "    _peerdb_is_deleted,\n",
        "    _peerdb_version\n",
        "FROM \"chipchip\".\"orders\"\n",
        "WHERE _peerdb_is_deleted = 0\n",
        "ORDER BY created_at DESC\n",
        "LIMIT 1000\n",
        "'''\n",
        "\n",
        "orders_data = make_superset_request(sql_query, \"ord\")\n",
        "if orders_data:\n",
        "    orders_df = pd.DataFrame(orders_data)\n",
        "    print(f\"‚úÖ Fetched {len(orders_df)} orders\")\n",
        "    print(f\"Order status distribution:\")\n",
        "    print(orders_df['status'].value_counts())\n",
        "    print(f\"Sample orders:\")\n",
        "    print(orders_df.head())\n",
        "else:\n",
        "    print(\"‚ùå No orders data fetched\")\n",
        "    orders_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# User-Level Segmentation Analysis\n",
        "if not orders_df.empty:\n",
        "    print(\"Performing user-level segmentation analysis...\")\n",
        "    \n",
        "    # Convert date columns\n",
        "    orders_df['created_at'] = pd.to_datetime(orders_df['created_at'], errors='coerce')\n",
        "    orders_df['total_amount'] = pd.to_numeric(orders_df['total_amount'], errors='coerce')\n",
        "    \n",
        "    # Calculate user metrics\n",
        "    current_date = datetime.now()\n",
        "    \n",
        "    # Group by user (using personal_cart_id as proxy for user_id)\n",
        "    user_metrics = []\n",
        "    \n",
        "    for cart_id in orders_df['personal_cart_id'].unique():\n",
        "        if pd.isna(cart_id):\n",
        "            continue\n",
        "            \n",
        "        user_orders = orders_df[orders_df['personal_cart_id'] == cart_id]\n",
        "        \n",
        "        if user_orders.empty:\n",
        "            continue\n",
        "        \n",
        "        # Calculate RFM metrics\n",
        "        recency = (current_date - user_orders['created_at'].max()).days\n",
        "        frequency = len(user_orders)\n",
        "        monetary = user_orders['total_amount'].sum() if 'total_amount' in user_orders.columns else 0\n",
        "        \n",
        "        # Average order value\n",
        "        avg_order_value = monetary / frequency if frequency > 0 else 0\n",
        "        \n",
        "        # Days since first order\n",
        "        days_since_first = (current_date - user_orders['created_at'].min()).days\n",
        "        \n",
        "        user_metrics.append({\n",
        "            'user_id': cart_id,\n",
        "            'recency': recency,\n",
        "            'frequency': frequency,\n",
        "            'monetary': monetary,\n",
        "            'avg_order_value': avg_order_value,\n",
        "            'days_since_first': days_since_first,\n",
        "            'total_orders': frequency\n",
        "        })\n",
        "    \n",
        "    user_df = pd.DataFrame(user_metrics)\n",
        "    print(f\"‚úÖ Analyzed {len(user_df)} users\")\n",
        "    print(f\"User metrics summary:\")\n",
        "    print(user_df.describe())\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No orders data available for user segmentation\")\n",
        "    user_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RFM Segmentation and Visualization\n",
        "if not user_df.empty:\n",
        "    print(\"Creating RFM segmentation...\")\n",
        "    \n",
        "    # Calculate RFM scores (1-5 scale)\n",
        "    user_df['recency_score'] = pd.qcut(user_df['recency'], 5, labels=[5,4,3,2,1])\n",
        "    user_df['frequency_score'] = pd.qcut(user_df['frequency'], 5, labels=[1,2,3,4,5])\n",
        "    user_df['monetary_score'] = pd.qcut(user_df['monetary'], 5, labels=[1,2,3,4,5])\n",
        "    \n",
        "    # Convert to numeric\n",
        "    user_df['recency_score'] = user_df['recency_score'].astype(int)\n",
        "    user_df['frequency_score'] = user_df['frequency_score'].astype(int)\n",
        "    user_df['monetary_score'] = user_df['monetary_score'].astype(int)\n",
        "    \n",
        "    # Create RFM segments\n",
        "    def assign_rfm_segment(row):\n",
        "        r, f, m = row['recency_score'], row['frequency_score'], row['monetary_score']\n",
        "        \n",
        "        if r >= 4 and f >= 4 and m >= 4:\n",
        "            return \"Champions\"\n",
        "        elif r >= 3 and f >= 4 and m >= 4:\n",
        "            return \"Loyal Customers\"\n",
        "        elif r >= 4 and f >= 2 and m >= 3:\n",
        "            return \"Potential Loyalists\"\n",
        "        elif r >= 4 and f >= 1 and m >= 1:\n",
        "            return \"New Customers\"\n",
        "        elif r >= 3 and f >= 2 and m >= 2:\n",
        "            return \"Promising\"\n",
        "        elif r >= 2 and f >= 2 and m >= 2:\n",
        "            return \"Need Attention\"\n",
        "        elif r >= 2 and f >= 1 and m >= 1:\n",
        "            return \"About to Sleep\"\n",
        "        elif r >= 1 and f >= 1 and m >= 1:\n",
        "            return \"At Risk\"\n",
        "        else:\n",
        "            return \"Lost\"\n",
        "    \n",
        "    user_df['rfm_segment'] = user_df.apply(assign_rfm_segment, axis=1)\n",
        "    \n",
        "    # Create RFM visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('RFM Segmentation Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. RFM Segment Distribution\n",
        "    segment_counts = user_df['rfm_segment'].value_counts()\n",
        "    axes[0, 0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 0].set_title('RFM Segment Distribution')\n",
        "    \n",
        "    # 2. Recency vs Frequency\n",
        "    scatter = axes[0, 1].scatter(user_df['recency'], user_df['frequency'], \n",
        "                               c=user_df['recency_score'], cmap='viridis', alpha=0.6)\n",
        "    axes[0, 1].set_xlabel('Recency (Days)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title('Recency vs Frequency')\n",
        "    plt.colorbar(scatter, ax=axes[0, 1], label='Recency Score')\n",
        "    \n",
        "    # 3. Frequency vs Monetary\n",
        "    scatter2 = axes[1, 0].scatter(user_df['frequency'], user_df['monetary'], \n",
        "                                c=user_df['monetary_score'], cmap='plasma', alpha=0.6)\n",
        "    axes[1, 0].set_xlabel('Frequency')\n",
        "    axes[1, 0].set_ylabel('Monetary Value')\n",
        "    axes[1, 0].set_title('Frequency vs Monetary Value')\n",
        "    plt.colorbar(scatter2, ax=axes[1, 0], label='Monetary Score')\n",
        "    \n",
        "    # 4. Segment Statistics\n",
        "    segment_stats = user_df.groupby('rfm_segment').agg({\n",
        "        'recency': 'mean',\n",
        "        'frequency': 'mean',\n",
        "        'monetary': 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    segment_stats.plot(kind='bar', ax=axes[1, 1])\n",
        "    axes[1, 1].set_title('Average Metrics by Segment')\n",
        "    axes[1, 1].set_xlabel('RFM Segment')\n",
        "    axes[1, 1].set_ylabel('Average Value')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ RFM segmentation completed!\")\n",
        "    print(f\"RFM Segment distribution:\")\n",
        "    print(segment_counts)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No user data available for RFM segmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Product-Level Segmentation\n",
        "if not product_variations_df.empty:\n",
        "    print(\"Creating product-level segmentation...\")\n",
        "    \n",
        "    # Prepare product data for segmentation\n",
        "    product_df = product_variations_df.copy()\n",
        "    \n",
        "    # Convert numeric columns\n",
        "    product_df['stock'] = pd.to_numeric(product_df['stock'], errors='coerce')\n",
        "    product_df['weight'] = pd.to_numeric(product_df['weight'], errors='coerce')\n",
        "    \n",
        "    # Create product segments based on stock levels\n",
        "    product_df['stock_segment'] = pd.cut(\n",
        "        product_df['stock'], \n",
        "        bins=[0, 10, 50, 100, 500, float('inf')], \n",
        "        labels=['Low Stock', 'Limited', 'Adequate', 'High Stock', 'Overstocked']\n",
        "    )\n",
        "    \n",
        "    # Create weight segments\n",
        "    product_df['weight_segment'] = pd.cut(\n",
        "        product_df['weight'], \n",
        "        bins=[0, 0.5, 1, 2, 5, float('inf')], \n",
        "        labels=['Very Light', 'Light', 'Medium', 'Heavy', 'Very Heavy']\n",
        "    )\n",
        "    \n",
        "    # Create product clustering based on stock and weight\n",
        "    features = ['stock', 'weight']\n",
        "    X = product_df[features].fillna(0)\n",
        "    \n",
        "    if not X.empty:\n",
        "        # Standardize features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        \n",
        "        # Perform K-means clustering\n",
        "        n_clusters = 4\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        product_df['product_cluster'] = kmeans.fit_predict(X_scaled)\n",
        "        \n",
        "        # Assign cluster names\n",
        "        cluster_names = {\n",
        "            0: \"Standard Products\",\n",
        "            1: \"High-Stock Products\", \n",
        "            2: \"Heavy Products\",\n",
        "            3: \"Premium Products\"\n",
        "        }\n",
        "        product_df['cluster_segment'] = product_df['product_cluster'].map(cluster_names)\n",
        "    \n",
        "    print(\"‚úÖ Product segmentation completed!\")\n",
        "    print(f\"Stock segment distribution:\")\n",
        "    print(product_df['stock_segment'].value_counts())\n",
        "    print(f\"Weight segment distribution:\")\n",
        "    print(product_df['weight_segment'].value_counts())\n",
        "    if 'cluster_segment' in product_df.columns:\n",
        "        print(f\"Cluster segment distribution:\")\n",
        "        print(product_df['cluster_segment'].value_counts())\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No product data available for segmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Product Segmentation Visualizations\n",
        "if not product_variations_df.empty and 'stock_segment' in product_df.columns:\n",
        "    print(\"Creating product segmentation visualizations...\")\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Product Segmentation Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Stock Segment Distribution\n",
        "    stock_counts = product_df['stock_segment'].value_counts()\n",
        "    axes[0, 0].pie(stock_counts.values, labels=stock_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 0].set_title('Stock Segment Distribution')\n",
        "    \n",
        "    # 2. Weight Segment Distribution\n",
        "    weight_counts = product_df['weight_segment'].value_counts()\n",
        "    axes[0, 1].pie(weight_counts.values, labels=weight_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 1].set_title('Weight Segment Distribution')\n",
        "    \n",
        "    # 3. Stock vs Weight by Cluster\n",
        "    if 'cluster_segment' in product_df.columns:\n",
        "        for cluster in product_df['cluster_segment'].unique():\n",
        "            cluster_data = product_df[product_df['cluster_segment'] == cluster]\n",
        "            axes[1, 0].scatter(cluster_data['stock'], cluster_data['weight'], \n",
        "                             label=cluster, alpha=0.6)\n",
        "        axes[1, 0].set_xlabel('Stock Quantity')\n",
        "        axes[1, 0].set_ylabel('Weight')\n",
        "        axes[1, 0].set_title('Stock vs Weight by Cluster')\n",
        "        axes[1, 0].legend()\n",
        "    \n",
        "    # 4. Cluster Distribution\n",
        "    if 'cluster_segment' in product_df.columns:\n",
        "        cluster_counts = product_df['cluster_segment'].value_counts()\n",
        "        axes[1, 1].bar(cluster_counts.index, cluster_counts.values)\n",
        "        axes[1, 1].set_title('Product Cluster Distribution')\n",
        "        axes[1, 1].set_xlabel('Cluster')\n",
        "        axes[1, 1].set_ylabel('Number of Products')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Product segmentation visualizations created!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No product segmentation data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Dashboard with Plotly\n",
        "print(\"Creating interactive dashboard...\")\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('RFM Segments', 'Product Stock Segments', 'Product Weight Segments', 'Product Clusters'),\n",
        "    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
        "           [{\"type\": \"pie\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "# Add RFM segments\n",
        "if not user_df.empty and 'rfm_segment' in user_df.columns:\n",
        "    rfm_counts = user_df['rfm_segment'].value_counts()\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=rfm_counts.index, values=rfm_counts.values, name=\"RFM\"),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# Add product stock segments\n",
        "if not product_variations_df.empty and 'stock_segment' in product_df.columns:\n",
        "    stock_counts = product_df['stock_segment'].value_counts()\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=stock_counts.index, values=stock_counts.values, name=\"Stock\"),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Add product weight segments\n",
        "if not product_variations_df.empty and 'weight_segment' in product_df.columns:\n",
        "    weight_counts = product_df['weight_segment'].value_counts()\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=weight_counts.index, values=weight_counts.values, name=\"Weight\"),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Add product clusters\n",
        "if not product_variations_df.empty and 'cluster_segment' in product_df.columns:\n",
        "    cluster_counts = product_df['cluster_segment'].value_counts()\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=cluster_counts.index, y=cluster_counts.values, name=\"Clusters\"),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text=\"Product Segmentation Dashboard\",\n",
        "    showlegend=True,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Show interactive dashboard\n",
        "fig.show()\n",
        "\n",
        "print(\"‚úÖ Interactive dashboard created!\")\n",
        "print(\"üéâ Product segmentation analysis completed!\")\n",
        "print(\"üìä You can now explore the interactive charts above!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
