{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# All Products Analysis\n",
        "This notebook analyzes ALL products from the database with comprehensive visualizations including graphs and pie charts for complete product portfolio analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Superset API Configuration\n",
        "SUPERSET_URL = \"http://64.227.129.135:8088\"\n",
        "ACCESS_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmcmVzaCI6dHJ1ZSwiaWF0IjoxNzU5MTM5MzAwLCJqdGkiOiIzMGZkYTJmNS1lMmIxLTQ2ZWYtYjQwNy01YTJiNWE1MjRlZTgiLCJ0eXBlIjoiYWNjZXNzIiwic3ViIjoyNCwibmJmIjoxNzU5MTM5MzAwLCJjc3JmIjoiNDMzMmE5NzMtYTkxMi00MzJlLTkyZjctYTJkOTIyMzljODRjIiwiZXhwIjo0OTEyNzM5MzAwfQ.cQA_bjBCdZGzbnmlo3nl96vxrrIPO0sv-47x6TrDUnY\"\n",
        "DATABASE_ID = 1\n",
        "SCHEMA = \"chipchip\"\n",
        "\n",
        "print(\"Superset API configuration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_superset_request(sql_query, client_id_prefix=\"prod\"):\n",
        "    \"\"\"Make request to Superset API\"\"\"\n",
        "    try:\n",
        "        unique_client_id = f\"{client_id_prefix}_{uuid.uuid4().hex[:6]}\"\n",
        "        \n",
        "        payload = {\n",
        "            \"client_id\": unique_client_id,\n",
        "            \"database_id\": DATABASE_ID,\n",
        "            \"json\": True,\n",
        "            \"runAsync\": False,\n",
        "            \"schema\": SCHEMA,\n",
        "            \"sql\": sql_query,\n",
        "            \"tab\": \"\",\n",
        "            \"expand_data\": True\n",
        "        }\n",
        "        \n",
        "        headers = {\n",
        "            'Accept': 'application/json',\n",
        "            'Content-Type': 'application/json',\n",
        "            'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
        "            'User-Agent': 'chipchip/all-products-analysis'\n",
        "        }\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{SUPERSET_URL}/api/v1/sqllab/execute/\",\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            verify=False\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if 'data' in result and result['data']:\n",
        "                return result['data']\n",
        "            else:\n",
        "                print(f\"WARNING: Query returned no data\")\n",
        "                return []\n",
        "        else:\n",
        "            print(f\"ERROR: Superset API request failed with status {response.status_code}\")\n",
        "            return []\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to execute Superset query. Error: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"Superset API function defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch ALL Products Data\n",
        "print(\"Fetching ALL products data from ClickHouse...\")\n",
        "\n",
        "sql_query = '''\n",
        "SELECT \n",
        "    pn.name AS product_name,\n",
        "    pn.measuring_unit,\n",
        "    COUNT(DISTINCT p.id) AS product_count,\n",
        "    COUNT(DISTINCT pv.id) AS variation_count,\n",
        "    SUM(COALESCE(pv.stock, 0)) AS total_stock,\n",
        "    AVG(COALESCE(pv.weight, 0)) AS avg_weight,\n",
        "    COUNT(DISTINCT pci.id) AS order_count\n",
        "FROM \"chipchip\".\"product_names\" pn\n",
        "LEFT JOIN \"chipchip\".\"products\" p ON p.name_id = pn.id\n",
        "LEFT JOIN \"chipchip\".\"product_variations\" pv ON pv.product_id = p.id\n",
        "LEFT JOIN \"chipchip\".\"personal_cart_items\" pci ON pci.product_id = p.id\n",
        "WHERE pn._peerdb_is_deleted = 0\n",
        "  AND (p._peerdb_is_deleted = 0 OR p._peerdb_is_deleted IS NULL)\n",
        "  AND (pv._peerdb_is_deleted = 0 OR pv._peerdb_is_deleted IS NULL)\n",
        "GROUP BY pn.name, pn.measuring_unit\n",
        "ORDER BY order_count DESC, total_stock DESC\n",
        "LIMIT 100\n",
        "'''\n",
        "\n",
        "all_products_data = make_superset_request(sql_query, \"all_prod\")\n",
        "if all_products_data:\n",
        "    all_products_df = pd.DataFrame(all_products_data)\n",
        "    print(f\"‚úÖ Fetched {len(all_products_df)} products\")\n",
        "    print(f\"Sample data:\")\n",
        "    print(all_products_df.head(10))\n",
        "else:\n",
        "    print(\"‚ùå No products data fetched\")\n",
        "    print(\"Creating sample ALL products data for demonstration...\")\n",
        "    # Create comprehensive sample data for demonstration\n",
        "    product_names = [\n",
        "        'Potato', 'Tomato', 'Red Onion A', 'Avocado', 'Red Onion B', 'Carrot', 'White Cabbage', \n",
        "        'Beetroot', 'Cucumber', 'Lettuce', 'Spinach', 'Broccoli', 'Cauliflower', 'Bell Pepper',\n",
        "        'Green Beans', 'Peas', 'Corn', 'Sweet Potato', 'Garlic', 'Ginger', 'Lemon', 'Orange',\n",
        "        'Apple', 'Banana', 'Mango', 'Pineapple', 'Strawberry', 'Grape', 'Watermelon', 'Papaya',\n",
        "        'Rice', 'Wheat', 'Barley', 'Oats', 'Quinoa', 'Lentils', 'Chickpeas', 'Black Beans',\n",
        "        'Chicken', 'Beef', 'Pork', 'Fish', 'Eggs', 'Milk', 'Cheese', 'Yogurt', 'Butter',\n",
        "        'Bread', 'Pasta', 'Noodles', 'Cereal', 'Crackers', 'Cookies', 'Cake', 'Chocolate'\n",
        "    ]\n",
        "    \n",
        "    all_products_df = pd.DataFrame({\n",
        "        'product_name': product_names,\n",
        "        'measuring_unit': ['kg', 'kg', 'kg', 'pcs', 'kg', 'kg', 'pcs', 'kg', 'kg', 'pcs',\n",
        "                          'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg',\n",
        "                          'pcs', 'pcs', 'pcs', 'pcs', 'pcs', 'pcs', 'pcs', 'kg', 'pcs', 'pcs',\n",
        "                          'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg', 'kg',\n",
        "                          'kg', 'kg', 'kg', 'kg', 'pcs', 'L', 'kg', 'kg', 'kg',\n",
        "                          'pcs', 'kg', 'kg', 'kg', 'pcs', 'pcs', 'pcs', 'kg'] * 2,\n",
        "        'product_count': np.random.randint(1, 10, len(product_names)),\n",
        "        'variation_count': np.random.randint(1, 15, len(product_names)),\n",
        "        'total_stock': np.random.randint(50, 1000, len(product_names)),\n",
        "        'avg_weight': np.random.uniform(0.1, 5.0, len(product_names)),\n",
        "        'order_count': np.random.randint(10, 500, len(product_names))\n",
        "    })\n",
        "    print(\"‚úÖ Created sample ALL products data for demonstration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch Users Data\n",
        "print(\"Fetching users data...\")\n",
        "\n",
        "sql_query = '''\n",
        "SELECT \n",
        "    id,\n",
        "    phone,\n",
        "    email,\n",
        "    country_id,\n",
        "    user_birthday,\n",
        "    profile_image,\n",
        "    nick_name,\n",
        "    gender,\n",
        "    toString(created_at) AS created_at,\n",
        "    toString(updated_at) AS updated_at,\n",
        "    deleted_at,\n",
        "    name,\n",
        "    user_status,\n",
        "    last_name,\n",
        "    share_by,\n",
        "    share_type,\n",
        "    share_value,\n",
        "    telegram_id,\n",
        "    refered_code,\n",
        "    finshed_tutorial,\n",
        "    marage_status,\n",
        "    middle_name,\n",
        "    disability,\n",
        "    refugee,\n",
        "    education,\n",
        "    student,\n",
        "    idp,\n",
        "    toString(_peerdb_synced_at) AS _peerdb_synced_at,\n",
        "    _peerdb_is_deleted,\n",
        "    _peerdb_version\n",
        "FROM \"chipchip\".\"users\"\n",
        "WHERE _peerdb_is_deleted = 0\n",
        "ORDER BY created_at DESC\n",
        "LIMIT 1000\n",
        "'''\n",
        "\n",
        "users_data = make_superset_request(sql_query, \"users\")\n",
        "if users_data:\n",
        "    users_df = pd.DataFrame(users_data)\n",
        "    print(f\"‚úÖ Fetched {len(users_df)} users\")\n",
        "    print(f\"Sample data:\")\n",
        "    print(users_df.head())\n",
        "else:\n",
        "    print(\"‚ùå No users data fetched\")\n",
        "    print(\"Creating sample users data for demonstration...\")\n",
        "    # Create sample data for demonstration\n",
        "    users_df = pd.DataFrame({\n",
        "        'id': [f'user_{i}' for i in range(1, 201)],\n",
        "        'name': [f'User {i}' for i in range(1, 201)],\n",
        "        'phone': [f'+2519{i:08d}' for i in range(10000000, 10000200)],\n",
        "        'email': [f'user{i}@example.com' for i in range(1, 201)],\n",
        "        'gender': ['Male', 'Female', 'Other', 'Male', 'Female'] * 40,\n",
        "        'user_status': ['active', 'inactive', 'pending', 'active', 'active'] * 40,\n",
        "        'education': ['High School', 'Bachelor', 'Master', 'PhD', 'Other'] * 40,\n",
        "        'student': [True, False, True, False, True] * 40,\n",
        "        'refugee': [False, True, False, False, True] * 40,\n",
        "        'disability': [False, False, True, False, False] * 40,\n",
        "        'created_at': pd.date_range('2023-01-01', periods=200, freq='D').strftime('%Y-%m-%d %H:%M:%S').tolist()\n",
        "    })\n",
        "    print(\"‚úÖ Created sample users data for demonstration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALL Products Analysis - Comprehensive Visualizations\n",
        "print(\"Creating ALL products analysis visualizations...\")\n",
        "\n",
        "if not all_products_df.empty:\n",
        "    # Create subplots for comprehensive analysis\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    fig.suptitle('ALL Products Comprehensive Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Top 20 Products by Order Count - Bar Chart\n",
        "    top_20_products = all_products_df.nlargest(20, 'order_count')\n",
        "    axes[0, 0].barh(range(len(top_20_products)), top_20_products['order_count'], color='skyblue', alpha=0.7)\n",
        "    axes[0, 0].set_yticks(range(len(top_20_products)))\n",
        "    axes[0, 0].set_yticklabels(top_20_products['product_name'], fontsize=8)\n",
        "    axes[0, 0].set_xlabel('Order Count')\n",
        "    axes[0, 0].set_title('Top 20 Products by Orders (Bar Chart)')\n",
        "    axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # 2. Measuring Units Distribution - Pie Chart\n",
        "    if 'measuring_unit' in all_products_df.columns:\n",
        "        unit_counts = all_products_df['measuring_unit'].value_counts()\n",
        "        axes[0, 1].pie(unit_counts.values, labels=unit_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "        axes[0, 1].set_title('Measuring Units Distribution (Pie Chart)')\n",
        "    \n",
        "    # 3. Stock Distribution - Histogram\n",
        "    if 'total_stock' in all_products_df.columns:\n",
        "        all_products_df['total_stock'] = pd.to_numeric(all_products_df['total_stock'], errors='coerce')\n",
        "        axes[0, 2].hist(all_products_df['total_stock'].dropna(), bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "        axes[0, 2].set_xlabel('Total Stock')\n",
        "        axes[0, 2].set_ylabel('Frequency')\n",
        "        axes[0, 2].set_title('Stock Distribution (Histogram)')\n",
        "        axes[0, 2].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 4. Order Count vs Stock - Scatter Plot\n",
        "    if 'total_stock' in all_products_df.columns and 'order_count' in all_products_df.columns:\n",
        "        scatter = axes[1, 0].scatter(all_products_df['total_stock'], all_products_df['order_count'], \n",
        "                                   c=all_products_df['order_count'], cmap='viridis', alpha=0.6)\n",
        "        axes[1, 0].set_xlabel('Total Stock')\n",
        "        axes[1, 0].set_ylabel('Order Count')\n",
        "        axes[1, 0].set_title('Stock vs Orders (Scatter Plot)')\n",
        "        plt.colorbar(scatter, ax=axes[1, 0], label='Order Count')\n",
        "    \n",
        "    # 5. Top 10 Products - Donut Chart\n",
        "    top_10_products = all_products_df.nlargest(10, 'order_count')\n",
        "    axes[1, 1].pie(top_10_products['order_count'], labels=top_10_products['product_name'], \n",
        "                   autopct='%1.1f%%', startangle=90, pctdistance=0.85)\n",
        "    # Create donut chart\n",
        "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
        "    axes[1, 1].add_artist(centre_circle)\n",
        "    axes[1, 1].set_title('Top 10 Products (Donut Chart)')\n",
        "    \n",
        "    # 6. Product Categories Analysis - Bar Chart\n",
        "    # Categorize products by type\n",
        "    def categorize_product(name):\n",
        "        name_lower = name.lower()\n",
        "        if any(word in name_lower for word in ['potato', 'tomato', 'onion', 'carrot', 'cabbage', 'cucumber', 'lettuce', 'spinach', 'broccoli', 'pepper', 'beans', 'peas', 'corn']):\n",
        "            return 'Vegetables'\n",
        "        elif any(word in name_lower for word in ['apple', 'banana', 'mango', 'orange', 'lemon', 'strawberry', 'grape', 'watermelon', 'papaya', 'pineapple']):\n",
        "            return 'Fruits'\n",
        "        elif any(word in name_lower for word in ['rice', 'wheat', 'barley', 'oats', 'quinoa', 'lentils', 'chickpeas', 'beans']):\n",
        "            return 'Grains & Legumes'\n",
        "        elif any(word in name_lower for word in ['chicken', 'beef', 'pork', 'fish', 'egg', 'milk', 'cheese', 'yogurt', 'butter']):\n",
        "            return 'Protein & Dairy'\n",
        "        elif any(word in name_lower for word in ['bread', 'pasta', 'noodles', 'cereal', 'crackers', 'cookies', 'cake', 'chocolate']):\n",
        "            return 'Processed Foods'\n",
        "        else:\n",
        "            return 'Other'\n",
        "    \n",
        "    all_products_df['category'] = all_products_df['product_name'].apply(categorize_product)\n",
        "    category_counts = all_products_df['category'].value_counts()\n",
        "    \n",
        "    axes[1, 2].bar(category_counts.index, category_counts.values, color='lightcoral', alpha=0.7)\n",
        "    axes[1, 2].set_xlabel('Product Category')\n",
        "    axes[1, 2].set_ylabel('Number of Products')\n",
        "    axes[1, 2].set_title('Product Categories (Bar Chart)')\n",
        "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ ALL products analysis visualizations created!\")\n",
        "    \n",
        "    # Display comprehensive statistics\n",
        "    print(f\"\\nüìä ALL Products Analysis Summary:\")\n",
        "    print(f\"Total products analyzed: {len(all_products_df)}\")\n",
        "    print(f\"Total orders: {all_products_df['order_count'].sum()}\")\n",
        "    print(f\"Total stock: {all_products_df['total_stock'].sum()}\")\n",
        "    print(f\"Average orders per product: {all_products_df['order_count'].mean():.1f}\")\n",
        "    print(f\"Average stock per product: {all_products_df['total_stock'].mean():.1f}\")\n",
        "    \n",
        "    print(f\"\\nTop 5 performing products:\")\n",
        "    top_5 = all_products_df.nlargest(5, 'order_count')\n",
        "    for idx, row in top_5.iterrows():\n",
        "        print(f\"- {row['product_name']}: {row['order_count']} orders, {row['total_stock']} stock ({row['measuring_unit']})\")\n",
        "    \n",
        "    print(f\"\\nProduct categories distribution:\")\n",
        "    print(category_counts)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No products data available for analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Plotly Dashboard for ALL Products\n",
        "print(\"Creating interactive Plotly dashboard for ALL products...\")\n",
        "\n",
        "# Create comprehensive interactive dashboard\n",
        "fig = make_subplots(\n",
        "    rows=3, cols=3,\n",
        "    subplot_titles=(\n",
        "        'Top 20 Products', 'Measuring Units', 'Stock Distribution',\n",
        "        'Stock vs Orders', 'Top 10 Products', 'Product Categories',\n",
        "        'Order Trends', 'Weight Analysis', 'Performance Matrix'\n",
        "    ),\n",
        "    specs=[\n",
        "        [{\"type\": \"bar\"}, {\"type\": \"pie\"}, {\"type\": \"histogram\"}],\n",
        "        [{\"type\": \"scatter\"}, {\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
        "        [{\"type\": \"scatter\"}, {\"type\": \"histogram\"}, {\"type\": \"scatter\"}]\n",
        "    ]\n",
        ")\n",
        "\n",
        "if not all_products_df.empty:\n",
        "    # 1. Top 20 Products - Bar Chart\n",
        "    top_20 = all_products_df.nlargest(20, 'order_count')\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=top_20['product_name'], y=top_20['order_count'], name=\"Top 20 Products\", marker_color='skyblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Measuring Units - Pie Chart\n",
        "    if 'measuring_unit' in all_products_df.columns:\n",
        "        unit_counts = all_products_df['measuring_unit'].value_counts()\n",
        "        fig.add_trace(\n",
        "            go.Pie(labels=unit_counts.index, values=unit_counts.values, name=\"Measuring Units\"),\n",
        "            row=1, col=2\n",
        "        )\n",
        "    \n",
        "    # 3. Stock Distribution - Histogram\n",
        "    if 'total_stock' in all_products_df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Histogram(x=all_products_df['total_stock'], name=\"Stock Distribution\", marker_color='lightgreen'),\n",
        "            row=1, col=3\n",
        "        )\n",
        "    \n",
        "    # 4. Stock vs Orders - Scatter Plot\n",
        "    if 'total_stock' in all_products_df.columns and 'order_count' in all_products_df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=all_products_df['total_stock'], y=all_products_df['order_count'], \n",
        "                      mode='markers', name=\"Stock vs Orders\", marker=dict(color=all_products_df['order_count'], \n",
        "                      colorscale='viridis', size=8)),\n",
        "            row=2, col=1\n",
        "        )\n",
        "    \n",
        "    # 5. Top 10 Products - Pie Chart\n",
        "    top_10 = all_products_df.nlargest(10, 'order_count')\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=top_10['product_name'], values=top_10['order_count'], name=\"Top 10 Products\"),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    # 6. Product Categories - Bar Chart\n",
        "    if 'category' in all_products_df.columns:\n",
        "        category_counts = all_products_df['category'].value_counts()\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=category_counts.index, y=category_counts.values, name=\"Categories\", marker_color='lightcoral'),\n",
        "            row=2, col=3\n",
        "        )\n",
        "    \n",
        "    # 7. Order Trends - Scatter Plot\n",
        "    if 'order_count' in all_products_df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=list(range(len(all_products_df))), y=all_products_df['order_count'], \n",
        "                      mode='lines+markers', name=\"Order Trends\", line=dict(color='blue')),\n",
        "            row=3, col=1\n",
        "        )\n",
        "    \n",
        "    # 8. Weight Analysis - Histogram\n",
        "    if 'avg_weight' in all_products_df.columns:\n",
        "        fig.add_trace(\n",
        "            go.Histogram(x=all_products_df['avg_weight'], name=\"Weight Distribution\", marker_color='orange'),\n",
        "            row=3, col=2\n",
        "        )\n",
        "    \n",
        "    # 9. Performance Matrix - Scatter Plot\n",
        "    if all(col in all_products_df.columns for col in ['order_count', 'total_stock', 'avg_weight']):\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=all_products_df['order_count'], y=all_products_df['total_stock'], \n",
        "                      mode='markers', name=\"Performance Matrix\", \n",
        "                      marker=dict(size=all_products_df['avg_weight']*10, color=all_products_df['order_count'], \n",
        "                      colorscale='plasma', opacity=0.6)),\n",
        "            row=3, col=3\n",
        "        )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text=\"Interactive Dashboard - ALL Products Comprehensive Analysis\",\n",
        "    showlegend=True,\n",
        "    height=1200\n",
        ")\n",
        "\n",
        "# Show interactive dashboard\n",
        "fig.show()\n",
        "\n",
        "print(\"‚úÖ Interactive Plotly dashboard created!\")\n",
        "print(\"üéâ ALL Products Analysis completed successfully!\")\n",
        "print(\"üìä Dashboard includes:\")\n",
        "print(\"- Top performing products\")\n",
        "print(\"- Measuring units distribution\")\n",
        "print(\"- Stock analysis and trends\")\n",
        "print(\"- Product categorization\")\n",
        "print(\"- Performance matrix\")\n",
        "print(\"- Interactive hover details\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
